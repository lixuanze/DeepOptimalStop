{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "American_Options_lower_bound.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqH_FvLm8zpR",
        "colab_type": "code",
        "outputId": "599185a3-6ed4-4643-aa5a-2a9d45dda1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#import simulation as sl\n",
        "import time as t\n",
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01QH5Aw99JCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiBrownian(M, N, dim, T):\n",
        "    '''\n",
        "    A multidimensional independent Brownian motion.\n",
        "    M: Number of samples.\n",
        "    N: Number of periods.\n",
        "    dim: Dimension of the brownian motion.\n",
        "    T: Time interval\n",
        "    '''\n",
        "    \n",
        "    dt = tf.convert_to_tensor(T / (N-1), dtype=tf.float64)\n",
        "    Z = tf.math.sqrt(dt) * tf.random.normal((M, N, dim), dtype=tf.float64)\n",
        "    return tf.math.cumsum(Z, axis=1, exclusive= True)\n",
        "\n",
        "def geometricBM(nb_samples, nb_periods, dim, T, S0, rate, div_yield, sigma, corr):\n",
        "    '''\n",
        "    This function will simulate a geometric BM\n",
        "    \n",
        "    S0: Initial value. shape = (dim)\n",
        "    rate: Risk free interest rate (scalar).\n",
        "    div_yield: Dividends yields. shape = (dim)\n",
        "    sigma: Volatilities. shape = (dim)\n",
        "    corr: Correlation matrix. shape = (dim, dim) \n",
        "    '''\n",
        "    # convert to tensor\n",
        "    S0 = tf.convert_to_tensor(S0, dtype=tf.float64)\n",
        "    div_yield = tf.convert_to_tensor(div_yield, dtype=tf.float64)\n",
        "    sigma = tf.convert_to_tensor(sigma, dtype=tf.float64)\n",
        "    corr = tf.convert_to_tensor(corr, dtype=tf.float64)\n",
        "        \n",
        "    # time grid\n",
        "    t = tf.range(0, T + T / nb_periods, T / (nb_periods - 1), dtype=tf.float64) \n",
        "    t = tf.reshape(t, [nb_periods, 1])\n",
        "    \n",
        "    # drift\n",
        "    u = rate - div_yield - sigma ** 2 / 2\n",
        "    u = tf.reshape(u, [1, dim])\n",
        "\n",
        "    # get brownian motion\n",
        "    BM = multiBrownian(nb_samples, nb_periods, dim, T)    \n",
        "    \n",
        "    if dim > 1:\n",
        "        # covariance matrix -------------------\n",
        "        #temp = sigma[None] * sigma[:, None]\n",
        "        #cov = tf.multiply(temp, corr)\n",
        "        #A = tf.linalg.cholesky(cov)\n",
        "\n",
        "        # or\n",
        "        sigma_ = tf.reshape(sigma, [dim, 1])\n",
        "        A = tf.linalg.cholesky(corr)\n",
        "        A = tf.multiply(A, sigma_)\n",
        "        # -------------------------------------        \n",
        "        diffusion_term = tf.linalg.matvec(A, BM)  \n",
        "    else:\n",
        "        diffusion_term = sigma*BM\n",
        "    \n",
        "    res = tf.math.exp(u*t  + diffusion_term)    \n",
        "    return S0 * res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOoTdBIS_F7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def payoff (tau, x, var_compute = False):\n",
        "    '''\n",
        "    The payoff of the option\n",
        "    Tau will be a vector one of the positions in the array of x\n",
        "    '''\n",
        "    #print(\"Tau\")\n",
        "    #print(tau)\n",
        "    #print(\"X\")\n",
        "    #print(x)\n",
        "   # print(\"MAX\")\n",
        "    #print(tf.math.reduce_max(x, axis = 2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    P = tf.math.reduce_max(x, axis = 2) - K\n",
        "    #print(\"Values of P\")\n",
        "    #print(P)\n",
        "    if type(tau) == int:\n",
        "         P = P[:,tau]   \n",
        "    else: #In the event of receiving an array of stopping times\n",
        "        t1 = tf.range(P.shape[0], dtype = int_type)\n",
        "        Indx = tf.stack((t1, tau), axis=1)\n",
        "        P = tf.gather_nd(P,Indx)\n",
        "    #print(\"P filter with tau\")\n",
        "    #print(P)\n",
        "    \n",
        "    t2 = tf.cast(tau, float_type)        \n",
        "    \n",
        "    I = tf.math.greater(P,0)\n",
        "    I = tf.where(I, 1.0, 1.0*0)\n",
        "    \n",
        "    I = tf.cast(I, float_type)\n",
        "    #print('I = ')\n",
        "    #print(I)\n",
        "    #print('multiply')\n",
        "    #print(I*P)\n",
        "    #print(tf.multiply(I,P))\n",
        "    #print(r *t2*T/n)\n",
        "    \n",
        "    pay = tf.convert_to_tensor(tf.exp(-r * t2*T/n), dtype = float_type)*tf.multiply(I,P)\n",
        "    #print(\"Mean\")\n",
        "    #print(tf.reduce_mean(pay))\n",
        "    #return\n",
        "    #print(tf.reduce_mean(pay))\n",
        "    #return\n",
        "    if var_compute:\n",
        "        return pay\n",
        "    else:\n",
        "        return tf.reduce_mean(pay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2wbUL_njwAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "def confident_interval(sigma, K, alpha = 0.05):\n",
        "    '''\n",
        "    This function will return\n",
        "    z_(alpha/2) * sigma/sqrt(K)\n",
        "    '''\n",
        "    return stats.norm.ppf(1-alpha/2)*sigma/np.sqrt(K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstZZWrQ_V5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Pricer:\n",
        "    '''\n",
        "    This class will initializate each child with a diferent Neural Network\n",
        "    This way it can change each child's loss function\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, n):\n",
        "        self.NN = [NeuralNet(i + 1) for i in range(n)]\n",
        "        self.n = n\n",
        "        self.this_stop_time = self.n*tf.ones(batch_size*training_size, dtype = int_type)\n",
        "        \n",
        "    def update_stop_time (self, n, X):\n",
        "        f = tf.squeeze(self.NN[n].run(X, batch_size, training_size))\n",
        "        f = tf.cast(f, dtype = int_type)\n",
        "        self.this_stop_time = n * f + self.this_stop_time * (1 - f)\n",
        "    \n",
        "    def train(self):\n",
        "        print('Getting X')\n",
        "        start = t.time()\n",
        "        X = geometricBM(batch_size*training_size, n+1, d, T, S0, r, delta, sigma, pho)\n",
        "        #X = sl.simulate_x (batch_size*training_size, n+1, d, T, S0, r, delta, sigma, pho)\n",
        "        input_nn = tf.Variable(X, name = 'x', dtype = float_type)\n",
        "        for i in range(self.n - 1, -1, -1):\n",
        "            print('Training layer i = ')\n",
        "            print(i)\n",
        "            self.NN[i].network_learn(input_nn, self.this_stop_time)\n",
        "            \n",
        "            self.update_stop_time(i, input_nn)\n",
        "        print('End of training, time in seconds from generating paths = ' + str(t.time() - start))\n",
        "\n",
        "    def lower_bound(self, Kl, t_size):    \n",
        "        X = geometricBM(Kl * t_size, n+1, d, T, S0, r, delta, sigma, pho)\n",
        "        #X = sl.simulate_x (Kl * t_size, n+1, d, T, S0, r, delta, sigma, pho)\n",
        "            \n",
        "        input_nn = tf.Variable(X, name = 'x', dtype = float_type)\n",
        "        s = []\n",
        "        for i in range(self.n):\n",
        "            s.append( self.NN[i].run(input_nn, Kl, t_size))\n",
        "        s.append(tf.ones([Kl * t_size], dtype = int_type)) \n",
        "        #print(s)\n",
        "        \n",
        "        tau = 0\n",
        "        for i in range(self.n + 1):\n",
        "            p = 1\n",
        "            for j in range(i):\n",
        "                p *= 1 - s[j]\n",
        "            \n",
        "            tau += i * s[i] * p\n",
        "        #print(\"TAU\")    \n",
        "        #print(tau)\n",
        "        #print(\"S\")\n",
        "        #print(s)\n",
        "        L = payoff (tf.squeeze(tau), input_nn, var_compute = True)\n",
        "        \n",
        "\n",
        "        L_mean = tf.reduce_mean(L)\n",
        "        \n",
        "        sig = (L - L_mean)**2\n",
        "        sig = tf.sqrt(tf.math.reduce_sum(sig)/(Kl * t_size - 1))\n",
        "        \n",
        "        print(L_mean)\n",
        "        return L_mean, sig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVQd58eu9ewV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet:\n",
        "    '''\n",
        "    This class will be responsable for each individual neural network\n",
        "    In our model, it will be the F^(theta_n)\n",
        "    '''\n",
        "    def __init__(self, n):\n",
        "        xavier=tf.keras.initializers.GlorotUniform()\n",
        "        self.l1=tf.keras.layers.Dense(40 + d, kernel_initializer = xavier, activation=tf.nn.relu,input_shape=[n,d], dtype = float_type)\n",
        "        self.l2=tf.keras.layers.Dense(40 + d, kernel_initializer = xavier,activation=tf.nn.relu, dtype = float_type)\n",
        "        self.out=tf.keras.layers.Dense(1,kernel_initializer = xavier,activation = tf.nn.sigmoid, dtype = float_type)\n",
        "        self.train_op = tf.keras.optimizers.Adam(100)\n",
        "        self.n = n\n",
        "        self.stop_time = []\n",
        "        \n",
        "        \n",
        "    # Running the model\n",
        "    def run(self,X, b_size, t_size): \n",
        "      ans = []\n",
        "      \n",
        "      for i in range(t_size):\n",
        "        X_test = X[i*b_size:(i + 1)*b_size]\n",
        "        boom=self.l1(X_test)\n",
        "        boom1=self.l2(boom)\n",
        "        boom2=self.out(boom1)\n",
        "        \n",
        "        boom2 = tf.where(tf.greater(boom2, 0.5), 1, 0)\n",
        "        ans.append(tf.cast(boom2[:,(self.n)], int_type)[:,0])\n",
        "      \n",
        "      return tf.concat(ans, axis = 0)\n",
        "\n",
        "      \n",
        "    #Custom loss fucntion\n",
        "    #Change this for each n\n",
        "    def get_loss(self,X):\n",
        "        boom=self.l1(X)\n",
        "        boom1=self.l2(boom)\n",
        "        boom2=self.out(boom1)\n",
        "        #print(self.n)\n",
        "\n",
        "        #print(self.stop_time)\n",
        "        #for i in range(10):\n",
        "        #  print(\"TAU = \" + str(i))\n",
        "        #print(payoff(self.stop_time,X))\n",
        "        r = payoff(self.n-1,X)*boom2 +  payoff(self.stop_time,X)*(1-boom2)\n",
        "        #print(r)\n",
        "        return -r\n",
        "      \n",
        "    # get gradients\n",
        "    def get_grad(self,X):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(self.l1.variables)\n",
        "            tape.watch(self.l2.variables)\n",
        "            tape.watch(self.out.variables)\n",
        "            L = self.get_loss(X)\n",
        "            g = tape.gradient(L, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]])\n",
        "        return g\n",
        "      \n",
        "    # perform gradient descent\n",
        "    def network_learn(self,X, stop_time):\n",
        "        for i in range(training_size):   \n",
        "            self.stop_time = stop_time[i*batch_size:(i + 1)*batch_size]\n",
        "            g = self.get_grad(X[i*batch_size:(i + 1)*batch_size])\n",
        "            #print('L1 - Variables')\n",
        "            #print(\"Before\")\n",
        "            #print(self.l1.variables)\n",
        "            self.train_op.apply_gradients(zip(g, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]]))\n",
        "            #print(\"AFTER\")\n",
        "            #print(self.l1.variables)\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldKAnLJw_bsu",
        "colab_type": "code",
        "outputId": "e5de68b3-5b0d-4813-8d59-f4ab7313146f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "float_type = tf.float64\n",
        "int_type = tf.int64\n",
        "\n",
        "n = 9\n",
        "d = 2\n",
        "T = 3\n",
        "S0 = 100*tf.ones(d, dtype=float_type)\n",
        "r = 0.05\n",
        "delta = 0.1*tf.ones(d, dtype=float_type)\n",
        "sigma = 0.2*tf.ones(d, dtype=float_type)\n",
        "pho = tf.linalg.diag(tf.ones(d, dtype = float_type))\n",
        "K = 100\n",
        "\n",
        "batch_size = 2**12\n",
        "training_size = 100\n",
        "P = Pricer(n) \n",
        "for i in range(1):\n",
        "#  clear_output(wait = True)\n",
        " \n",
        "  P.train()\n",
        "  print(str(i) + ' The price is: ')\n",
        "  Kl = 10000\n",
        "  L, sig = P.lower_bound(Kl,10)\n",
        "  \n",
        "  print(\"Variance is = \")\n",
        "  print(sig)\n",
        "  print(\"Confidence Interval = \")\n",
        "  print(confident_interval(sig, Kl))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting X\n",
            "Training layer i = \n",
            "8\n",
            "Training layer i = \n",
            "7\n",
            "Training layer i = \n",
            "6\n",
            "Training layer i = \n",
            "5\n",
            "Training layer i = \n",
            "4\n",
            "Training layer i = \n",
            "3\n",
            "Training layer i = \n",
            "2\n",
            "Training layer i = \n",
            "1\n",
            "Training layer i = \n",
            "0\n",
            "End of training, time in seconds from generating paths = 14.237515687942505\n",
            "0 The price is: \n",
            "tf.Tensor(20.933649773711455, shape=(), dtype=float64)\n",
            "Variance is = \n",
            "tf.Tensor(29.136149711599874, shape=(), dtype=float64)\n",
            "Confidence Interval = \n",
            "tf.Tensor(0.5710580408290283, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXbdks4-yNTI",
        "colab_type": "code",
        "outputId": "07d2809a-5101-43ba-e3eb-671d508b801d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for i in range(1):\n",
        "#  clear_output(wait = True)\n",
        " \n",
        "  \n",
        "  print(str(i) + ' The price is: ')\n",
        "  Kl = 100000\n",
        "  L, sig = P.lower_bound(Kl,100)\n",
        "  \n",
        "  print(\"Variance is = \")\n",
        "  print(sig)\n",
        "  print(\"Confidence Interval = \")\n",
        "  print(confident_interval(sig, Kl))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 The price is: \n",
            "tf.Tensor(20.921934009338848, shape=(), dtype=float64)\n",
            "Variance is = \n",
            "tf.Tensor(29.167238242954877, shape=(), dtype=float64)\n",
            "Confidence Interval = \n",
            "tf.Tensor(0.1807770936902706, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh0awLu603xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}